{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ner_1_2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgDUExqz5ioj"
      },
      "source": [
        "Set up Google Colab Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3chPOl3o5MrV",
        "outputId": "b5db5421-6197-4248-fbc7-9e3b7cb21955"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXJqiu7P6T2p"
      },
      "source": [
        "Deep learning needs the computational power of GPUs, therefore, we run this notebook on Google Colab with GPU support.<br>\n",
        "Check RAM of GPU.<br>\n",
        "For this end, we need to install [GPUtil](https://pypi.org/project/GPUtil/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gumhOAG16vYh",
        "outputId": "adb96a4b-bcbc-4832-9905-5133536dbde2"
      },
      "source": [
        "pip install GPUtil"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=d54b7c9350cc6f3a2ce6abd5a235a7d0042a62579d25b225118cca9c9818b712\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkK4Lfch6MGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae3a236-8668-44cb-c23e-a94b2d3f2b14"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.7 GB  I Proc size: 118.6 MB\n",
            "GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total 15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-quF-P-XXH"
      },
      "source": [
        "Change directory to \"/flair\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BBTFZUFp_fY2",
        "outputId": "73d85f88-4b47-467e-ae4e-163ac8715cb9"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRq9VJeA_sSH"
      },
      "source": [
        "So, we are currently in \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1VO3JH8ADUt"
      },
      "source": [
        "#for directory in os.walk( os.getcwd() ):\n",
        "  #print( directory )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhCgEKfqA8mU"
      },
      "source": [
        "We see in the table above, that there exists a folder \"/content/gdrive/MyDrive/flair\" into which we have loaded our data.<br>\n",
        "We now change the working directory to this directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefqzTtQA229"
      },
      "source": [
        "os.chdir( \"/content/gdrive/MyDrive/flair\" ) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r88--TlKBW9r",
        "outputId": "736ce641-45b5-44ea-dc93-9a4504c7ea9c"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/flair'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pus5Y1jfhf-D"
      },
      "source": [
        "Using the code from above, we change the current working directory to the directory, where we loaded our data to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KpNb75WC1RS",
        "outputId": "69cca69b-637b-4ee7-def1-b3abcad5f6d7"
      },
      "source": [
        "os.listdir( os.getcwd() )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Entity Recognition in Resumes.json',\n",
              " '.ipynb_checkpoints',\n",
              " 'training_data.csv',\n",
              " 'test_data.csv',\n",
              " 'flair_glove']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvSVxTV4ERCb"
      },
      "source": [
        "Install Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6UgvIiOET3h",
        "outputId": "d2b89e2c-3b3c-4874-b50b-5093e87c28f2"
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/3a/1b46a0220d6176b22bcb9336619d1731301bc2c75fa926a9ef953e6e4d58/flair-0.8.0.post1-py3-none-any.whl (284kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 26.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 22.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 25.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 24.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 25.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 22.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 23.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92kB 22.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 23.3MB/s \n",
            "\u001b[?25hCollecting gdown==3.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/b5/5da463f9c7823e0e575e9908d004e2af4b36efa8d02d3d6dad57094fcb11/ftfy-6.0.1.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 50.8MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.1MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/be/4dd30d56a0a19619deb9bf41ba8202709fa83b1b301b876572cd6dc38117/konoha-4.6.4-py3-none-any.whl\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting transformers>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 41.9MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/32/a1/7c5261396da23ec364e296a4fb8a1cd6a5a2ff457215c6447038f18c0309/huggingface_hub-0.0.9-py3-none-any.whl\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/bpemb/\u001b[0m\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/6f/9191b85109772636a8f8accb122900c34db26c091d2793218aa94954524c/bpemb-0.3.3-py3-none-any.whl\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/52/d0/bdb31463f2d9ca111e39b268518e9baa3542ef73ca449b711a7b4da69764/importlib_metadata-3.10.1-py3-none-any.whl\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (8.0.0)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=638715bd401d62c3afb444ee37da29427bfd23269048294b03454dde58b0ebd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: ftfy, segtok, mpld3, langdetect, sqlitedict, overrides\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-cp37-none-any.whl size=41573 sha256=093421faa4e1691d7a51dddea427e5ae79d3eadd90b12cd64acb1ec33cd29029\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/73/c7/9056e14b04919e5c262fe80b54133b1a88d73683d05d7ac65c\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=7d1e518321da63d2b25f8f0ff2bdaa71da5cb81058669b31e2f3e5ef163e9032\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116679 sha256=4c241f55c98d3e12f64270aa4eb2ae631d3d2fcfe31800244774bf3544dbbe23\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993223 sha256=d016ccabd9ed08850bfa6e7e99f32ed3dbe9b11e5a3bee8c96b957f7faab8d3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14376 sha256=2d6cfdf2e34e20e54c3fd46acd3141c9ad38da2ae2f26f7c73385adf0559c3a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=bedcdbef524605993a39d29582271dfe8bfd41ff69219f773981b9fd6b3e9a2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built ftfy segtok mpld3 langdetect sqlitedict overrides\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: konoha 4.6.4 has requirement requests<3.0.0,>=2.25.1, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: transformers 4.6.1 has requirement huggingface-hub==0.0.8, but you'll have huggingface-hub 0.0.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gdown, sentencepiece, ftfy, deprecated, segtok, mpld3, janome, importlib-metadata, overrides, konoha, langdetect, sacremoses, tokenizers, huggingface-hub, transformers, torch, bpemb, sqlitedict, flair\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "  Found existing installation: importlib-metadata 4.0.1\n",
            "    Uninstalling importlib-metadata-4.0.1:\n",
            "      Successfully uninstalled importlib-metadata-4.0.1\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.1 gdown-3.12.2 huggingface-hub-0.0.9 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.4 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.2 torch-1.7.1 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbUtk3gUIUH"
      },
      "source": [
        "Import the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hwSlDozTvTu"
      },
      "source": [
        "path_to_data = os.getcwd() + '/Entity Recognition in Resumes.json'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbJWMuBEhf-E"
      },
      "source": [
        "__Task 1__: Complete the following code: we want to read the data from said .json-file into the list __imported_data__. Also, print the first line, so that we get an idea, what the data look like. Also, print how many resumees we got."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StK5oNS8Uo7G",
        "outputId": "8bde36af-9846-4357-afb2-f7a4c70c9803"
      },
      "source": [
        "myfile = open( path_to_data, \"r\", encoding = \"utf-8\" )\n",
        "\n",
        "imported_data = []\n",
        "\n",
        "for datum in myfile:\n",
        "    \n",
        "    # TODO process data\n",
        "    imported_data.append(datum)\n",
        "\n",
        "myfile.close()\n",
        "\n",
        "# TODO print first line\n",
        "print(imported_data[0])\n",
        "\n",
        "# TODO print how many resumees were read in\n",
        "print(len(imported_data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"content\": \"Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\",\"annotation\":[{\"label\":[\"Email Address\"],\"points\":[{\"start\":1155,\"end\":1198,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Links\"],\"points\":[{\"start\":1143,\"end\":1239,\"text\":\"https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\"}]},{\"label\":[\"Skills\"],\"points\":[{\"start\":743,\"end\":1140,\"text\":\"Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":729,\"end\":732,\"text\":\"2016\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":675,\"end\":702,\"text\":\"Shivaji University Kolhapur \"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":631,\"end\":672,\"text\":\"Bachelor of Engg in Information Technology\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":625,\"end\":629,\"text\":\"2017\\n\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":614,\"end\":622,\"text\":\"CDAC ACTS\"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":606,\"end\":611,\"text\":\"PG-DAC\"}]},{\"label\":[\"Companies worked at\"],\"points\":[{\"start\":438,\"end\":453,\"text\":\"Cisco Networking\"}]},{\"label\":[\"Email Address\"],\"points\":[{\"start\":104,\"end\":147,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Location\"],\"points\":[{\"start\":62,\"end\":67,\"text\":\"Sangli\"}]},{\"label\":[\"Name\"],\"points\":[{\"start\":0,\"end\":13,\"text\":\"Afreen Jamadar\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1527844872000,\"last_updated_at\":1537724086000,\"sec_taken\":0,\"last_updated_by\":\"BIQNZm4INNfvByMqkaVwVt6OZTv2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\n",
            "\n",
            "701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ZSnIfOWLP_"
      },
      "source": [
        "Map the dataset to json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We0edT5BWRTv"
      },
      "source": [
        "import json"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "GxHO13ySkgg6",
        "outputId": "c9ac61ee-dc4e-4a75-9b65-6c2840c175d9"
      },
      "source": [
        "imported_data[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"content\": \"Afreen Jamadar\\\\nActive member of IIIT Committee in Third year\\\\n\\\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\\\n\\\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\\\nand work to excellence in my work.\\\\n\\\\nWORK EXPERIENCE\\\\n\\\\nActive member of IIIT Committee in Third year\\\\n\\\\nCisco Networking -  Kanpur, Uttar Pradesh\\\\n\\\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\\\nPERSONALLITY TRAITS:\\\\n• Quick learning ability\\\\n• hard working\\\\n\\\\nEDUCATION\\\\n\\\\nPG-DAC\\\\n\\\\nCDAC ACTS\\\\n\\\\n2017\\\\n\\\\nBachelor of Engg in Information Technology\\\\n\\\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\\\n\\\\n2016\\\\n\\\\nSKILLS\\\\n\\\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\\\n\\\\nADDITIONAL INFORMATION\\\\n\\\\nTECHNICAL SKILLS:\\\\n\\\\n• Programming Languages: C, C++, Java, .net, php.\\\\n• Web Designing: HTML, XML\\\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\\\n\\\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\",\"annotation\":[{\"label\":[\"Email Address\"],\"points\":[{\"start\":1155,\"end\":1198,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Links\"],\"points\":[{\"start\":1143,\"end\":1239,\"text\":\"https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\"}]},{\"label\":[\"Skills\"],\"points\":[{\"start\":743,\"end\":1140,\"text\":\"Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\\\n\\\\nADDITIONAL INFORMATION\\\\n\\\\nTECHNICAL SKILLS:\\\\n\\\\n• Programming Languages: C, C++, Java, .net, php.\\\\n• Web Designing: HTML, XML\\\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":729,\"end\":732,\"text\":\"2016\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":675,\"end\":702,\"text\":\"Shivaji University Kolhapur \"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":631,\"end\":672,\"text\":\"Bachelor of Engg in Information Technology\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":625,\"end\":629,\"text\":\"2017\\\\n\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":614,\"end\":622,\"text\":\"CDAC ACTS\"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":606,\"end\":611,\"text\":\"PG-DAC\"}]},{\"label\":[\"Companies worked at\"],\"points\":[{\"start\":438,\"end\":453,\"text\":\"Cisco Networking\"}]},{\"label\":[\"Email Address\"],\"points\":[{\"start\":104,\"end\":147,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Location\"],\"points\":[{\"start\":62,\"end\":67,\"text\":\"Sangli\"}]},{\"label\":[\"Name\"],\"points\":[{\"start\":0,\"end\":13,\"text\":\"Afreen Jamadar\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1527844872000,\"last_updated_at\":1537724086000,\"sec_taken\":0,\"last_updated_by\":\"BIQNZm4INNfvByMqkaVwVt6OZTv2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI-fguXrWTvo"
      },
      "source": [
        "mapped_data = [ json.loads( datum ) for datum in imported_data  ]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_ut4zxhf-F"
      },
      "source": [
        "Now, the data are stored in __mapped_data__. __mapped_data__ is a list, and its entries are dictionaries.<br>\n",
        "__Task 2__: choose an entry of __mapped_data__, iterate over its keys, print the key and its corresponding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSHAxQFYBbp",
        "outputId": "75f0575b-64e8-4b56-d598-f111e6771dbc"
      },
      "source": [
        "#TODO choose an entry of mapped_data, iterate over its keys, print the key and its corresponding value\n",
        "for i, key in enumerate(mapped_data[27].keys()):\n",
        "  print(f\"[{i+1}] {key}: {mapped_data[27][key]}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] content: Kasturika Borah\n",
            "Team Member - Cisco\n",
            "\n",
            "Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Kasturika-\n",
            "Borah/9e71468914b38ee8\n",
            "\n",
            "• Software Engineer with overall 3+ years of experience in Network Monitoring system tool (EM7,\n",
            "Quicksilver) Database tool (SQL, Maria DB) and reporting tool (Splunk) in all the releases.\n",
            "• Relevant experience as a Test engineer for the releases includes Functional testing as well as\n",
            "regression testing. Testing includes writing test cases, execute them and raise bugs.\n",
            "• Relevant 1+ years of experience in handling releases for EM7 with proper documentation, Power\n",
            "pack creation and Tar creation for Sprint releases.\n",
            "• Creating Splunk reports from last 6 months.\n",
            "• Competent technical person involved in requirement gathering, analysis, design and coding.\n",
            "• Experience in coding Python, SQL, and XML as per the requirement.\n",
            "• Have knowledge in Event generating using traps and Syslog's generator.\n",
            "• Exposure to Agile methodologies using Scrum Works framework, even handled scrum in the\n",
            "team\n",
            "• Strong problem-solver who can design solutions and assist developers with issues.\n",
            "• Excellent debugging and resolution skills.\n",
            "• Good communication and interpersonal skills.\n",
            "\n",
            "• Working as Software Engineer for Cisco System India Private Ltd under Capgemini India Pvt.\n",
            "Ltd.. From May 25th 2017 till nowl\n",
            "• Working as Software Engineer for Cisco System India Private Ltd under Randstad India Ltd.\n",
            "From Dec 15 2014 till 30th April.\n",
            "• Worked as Data Analyst for Fidelity India Financial Inc. from June 2013 till Oct 2014.\n",
            "• Worked as Billing Analyst for IBM Daksh from March 2013 to June 2013.\n",
            "\n",
            "Willing to relocate to: Bengaluru, Karnataka\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Team Member\n",
            "\n",
            "Cisco -\n",
            "\n",
            "October 2017 to Present\n",
            "\n",
            "Environment: Splunk\n",
            "Technologies: SPL command\n",
            "\n",
            "Responsibilities\n",
            "• Involvement writing Splunk programming language and designing the report dashboard\n",
            "• Following Agile methodology\n",
            "• Develop the code on the design in splunk.\n",
            "• Unit Testing and code review\n",
            "\n",
            "Senior developer and tester\n",
            "\n",
            "https://www.indeed.com/r/Kasturika-Borah/9e71468914b38ee8?isid=rex-download&ikw=download-top&co=IN\n",
            "https://www.indeed.com/r/Kasturika-Borah/9e71468914b38ee8?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "Cisco -\n",
            "\n",
            "December 2014 to Present\n",
            "\n",
            "Environment: EM7 platform, Quicksilver, SQL, oracle Toad\n",
            "Technologies: Python coding, xml coding, SQL query writing\n",
            "\n",
            "Description\n",
            "Cisco Systems, Inc. (known as Cisco) is an American multinational technology conglomerate\n",
            "headquartered in San José, California, that develops, manufactures, and sells networking\n",
            "hardware, telecommunications equipment, and other high-technology services and products\n",
            "(www.cisco.com)\n",
            "\n",
            "Responsibilities\n",
            "1. Developer of individual task on each release by weekly\n",
            "• Need to do coding for new requirement.\n",
            "• Also need to do end to end testing of all the events including Traps and Syslogs.\n",
            "2. Database and Infrastructure Monitoring and Alerting related to device.\n",
            "3. Involvement in documentation of release notes and preparation of a Regression testing at the\n",
            "end of each release.\n",
            "\n",
            "Team Member\n",
            "\n",
            "Cisco -\n",
            "\n",
            "December 2014 to December 2017\n",
            "\n",
            "Environment: INFOVISTA (Vportal)\n",
            "Technologies: MS-Excel (sort, VLOOKUP), PPT\n",
            "\n",
            "Responsibilities\n",
            "• Involvement in generating performance reports for certain customers at the starting of every\n",
            "month\n",
            "• Gathering the data from the INFOVISTA portal and sort it out as per month in the excel and\n",
            "design the graphs for last consecutive\n",
            "• Responsible for each data uploaded to the excel sheet and reviewing it before delivering\n",
            "\n",
            "Fidelity national financial -\n",
            "\n",
            "June 2013 to October 2014\n",
            "\n",
            "Role: QA and Report handling for the team\n",
            "Technologies: MS-Excel (sort, VLOOKUP), PPT, MS-Outlook\n",
            "\n",
            "Responsibilities\n",
            "• Involvement in generating performance reports for the team at the end of each day and monthly\n",
            "based\n",
            "• Responsible for each data uploaded to the excel sheet and sending it to the team manager\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Compucom Insitute of Information Technology\n",
            "\n",
            "\n",
            "\n",
            "rajasthan University\n",
            "\n",
            "2012\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Database (3 years), Python (3 years), Splunk (Less than 1 year), SQL (3 years), xml (3 years)\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "TECHNICAL SKILLS\n",
            "\n",
            "• Programming Languages: Python, XML\n",
            "• Database: Maria-DB, sql\n",
            "• Cisco Monitoring Tools: EM7\n",
            "• Operating Systems: Windows/XP\n",
            "• Reporting Tools: Vportal, Splunk\n",
            "• Application & Web Servers: Sciencelogic (EM7), Syslog sender, Relay server.\n",
            "• Data Structure Knowledge: Intermediate\n",
            "[2] annotation: [{'label': ['Companies worked at'], 'points': [{'start': 4186, 'end': 4190, 'text': 'Cisco'}]}, {'label': ['Skills'], 'points': [{'start': 4121, 'end': 4398, 'text': '• Programming Languages: Python, XML\\n• Database: Maria-DB, sql\\n• Cisco Monitoring Tools: EM7\\n• Operating Systems: Windows/XP\\n• Reporting Tools: Vportal, Splunk\\n• Application & Web Servers: Sciencelogic (EM7), Syslog sender, Relay server.\\n• Data Structure Knowledge: Intermediate'}]}, {'label': ['Skills'], 'points': [{'start': 3984, 'end': 4077, 'text': 'Database (3 years), Python (3 years), Splunk (Less than 1 year), SQL (3 years), xml (3 years)\\n'}]}, {'label': ['Graduation Year'], 'points': [{'start': 3970, 'end': 3973, 'text': '2012'}]}, {'label': ['College Name'], 'points': [{'start': 3948, 'end': 3968, 'text': 'rajasthan University\\n'}]}, {'label': ['College Name'], 'points': [{'start': 3901, 'end': 3944, 'text': 'Compucom Insitute of Information Technology\\n'}]}, {'label': ['Companies worked at'], 'points': [{'start': 3061, 'end': 3065, 'text': 'Cisco'}]}, {'label': ['Designation'], 'points': [{'start': 3048, 'end': 3058, 'text': 'Team Member'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2402, 'end': 2406, 'text': 'Cisco'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2372, 'end': 2376, 'text': 'Cisco'}]}, {'label': ['Companies worked at'], 'points': [{'start': 2208, 'end': 2212, 'text': 'Cisco'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1690, 'end': 1694, 'text': 'Cisco'}]}, {'label': ['Designation'], 'points': [{'start': 1677, 'end': 1687, 'text': 'Team Member'}]}, {'label': ['Location'], 'points': [{'start': 1638, 'end': 1646, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1361, 'end': 1365, 'text': 'Cisco'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1233, 'end': 1237, 'text': 'Cisco'}]}, {'label': ['Email Address'], 'points': [{'start': 72, 'end': 125, 'text': 'Indeed: indeed.com/r/Kasturika-\\nBorah/9e71468914b38ee8'}]}, {'label': ['Location'], 'points': [{'start': 37, 'end': 45, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 30, 'end': 34, 'text': 'Cisco'}]}, {'label': ['Designation'], 'points': [{'start': 16, 'end': 26, 'text': 'Team Member'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 14, 'text': 'Kasturika Borah'}]}]\n",
            "[3] extras: None\n",
            "[4] metadata: {'first_done_at': 1527834155000, 'last_updated_at': 1527834155000, 'sec_taken': 94, 'last_updated_by': 'jI67aE5hwwdh6l16bcfFVnpyREd2', 'status': 'done', 'evaluation': 'NONE'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gp7URulapTm"
      },
      "source": [
        "__Question 1__: What are the keys, and what information do these keys store?<br>\n",
        "\n",
        "The keys of the mapped data are:\n",
        "  - content (stores the entire plane CV)\n",
        "  - annotations (holds additional information)\n",
        "  - extras (holds mostly nothing)\n",
        "  - metadata (information about creating and change time of the CV)\n",
        "\n",
        "And the keys for annotations are:\n",
        "  - label (the name of the label)\n",
        "    - e.g. Email\n",
        "    - e.g. Skills\n",
        "  - points (the location in the text with start and end string)\n",
        "\n",
        "__Task 3__: for each entry of __annotations__: iterate over the keys of this entry and print the key and the corresponding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9WcXpq4bTee",
        "outputId": "ed21e6ef-7b66-42c3-d175-2d097c0a8938"
      },
      "source": [
        "# TODO for each entry of annotations: iterate over the keys of this entry and print the key and the corresponding value\n",
        "\n",
        "def show_annotation_values(n):\n",
        "  for i in range(n):\n",
        "    datum = mapped_data[i]\n",
        "    for key in datum.keys():\n",
        "      if key == \"annotation\":\n",
        "        try:\n",
        "          for anno_key in datum[key][0].keys():\n",
        "            print(f\"[{i}] {anno_key}: {datum[key][0][anno_key]}\")\n",
        "        except:\n",
        "          print(\"No data\")\n",
        "\n",
        "show_annotation_values(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0] label: ['Email Address']\n",
            "[0] points: [{'start': 1155, 'end': 1198, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]\n",
            "[1] label: ['Skills']\n",
            "[1] points: [{'start': 8098, 'end': 8383, 'text': '❖ Operating Environment: […] Windows95/98/XP/NT\\n❖ Database Tool: SQL Management Studio (MSSQL), Business\\nDevelopment Studio, Visual studio 2005\\n❖ Database Language: SQL, PL/SQL\\n❖ Ticket Tracking Tool: Service Now\\n❖ Reporting Tools: MS Reporting Services, SAS\\n❖ Languages: C, C++, PL/SQL'}]\n",
            "[2] label: ['Links']\n",
            "[2] points: [{'start': 2881, 'end': 2930, 'text': 'https://www.linkedin.com/in/anvitha-d-rao-65a068a7'}]\n",
            "[3] label: ['Skills']\n",
            "[3] points: [{'start': 5088, 'end': 5108, 'text': 'interpersonal skills.'}]\n",
            "[4] label: ['Skills']\n",
            "[4] points: [{'start': 1970, 'end': 2082, 'text': '• Languages - Python\\n\\n• Software/Tools - Selenium, WAF, Sauce Labs, Jenkins, Creo parametric 2.0, Catia V6, Ansys'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i-ZPKiyfyrt"
      },
      "source": [
        "__Question 2__: What did you learn about the __annotations__? Give an example.<br>\n",
        "\n",
        "I learned that we can infer additional information about labels. The text from the labels are included in the CV with the according location, so we can build a training set out of this, because we have labeled annotate data.\n",
        "\n",
        "<br>\n",
        "\n",
        "__Task 4__: Complete the following code to map the __mapped_data__ to a format, from which Spacy can learn. Print the first converted resumee for inspection. Choose one resumee. For this resumee, print all the data in __entities__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzmu0XSOhybH",
        "outputId": "64c40f2a-6055-49ee-d5c3-fa789d5aa672"
      },
      "source": [
        "## data conversion method\n",
        "def convert_data(data):\n",
        "    \"\"\"\n",
        "    Creates NER training data in Spacy format from JSON dataset\n",
        "    Outputs the Spacy training data which can be used for Spacy training.\n",
        "    \"\"\"\n",
        "    text = data['content']\n",
        "    entities = []\n",
        "    if data['annotation'] is not None:\n",
        "        for annotation in data['annotation']:\n",
        "            # only a single point in text annotation.\n",
        "            point = annotation['points'][0]\n",
        "            labels = annotation['label']\n",
        "            # handle both list of labels or a single label.\n",
        "            if not isinstance(labels, list):\n",
        "                labels = [labels]\n",
        "            for label in labels:\n",
        "                # dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
        "                entities.append((point['start'], point['end'] + 1, label))\n",
        "    return (text, {\"entities\": entities})\n",
        "   \n",
        "## TODO using a loop or list comprehension, convert each resume in mapped_data using the convert function above, \n",
        "## storing the result\n",
        "converted_resumes = [convert_data(data) for data in mapped_data]\n",
        "## TODO print the number of resumes in converted resumes \n",
        "print(len(converted_resumes))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jO6WUBLiaD0",
        "outputId": "238044a5-9d76-41bf-8be4-6e5e844d588e"
      },
      "source": [
        "# TODO print the first resumee for inspection\n",
        "converted_resumes[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN',\n",
              " {'entities': [(1155, 1199, 'Email Address'),\n",
              "   (1143, 1240, 'Links'),\n",
              "   (743, 1141, 'Skills'),\n",
              "   (729, 733, 'Graduation Year'),\n",
              "   (675, 703, 'College Name'),\n",
              "   (631, 673, 'Degree'),\n",
              "   (625, 630, 'Graduation Year'),\n",
              "   (614, 623, 'College Name'),\n",
              "   (606, 612, 'Degree'),\n",
              "   (438, 454, 'Companies worked at'),\n",
              "   (104, 148, 'Email Address'),\n",
              "   (62, 68, 'Location'),\n",
              "   (0, 14, 'Name')]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "6FDv_kfXi4MF",
        "outputId": "53c32e43-85ee-4956-a61a-904d5a741479"
      },
      "source": [
        "# TODO choose one resumee. For this resumee, print all the data in entities. Use the dumps function from json.\n",
        "\n",
        "json.dumps(converted_resumes[27][1][\"entities\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[[4186, 4191, \"Companies worked at\"], [4121, 4399, \"Skills\"], [3984, 4078, \"Skills\"], [3970, 3974, \"Graduation Year\"], [3948, 3969, \"College Name\"], [3901, 3945, \"College Name\"], [3061, 3066, \"Companies worked at\"], [3048, 3059, \"Designation\"], [2402, 2407, \"Companies worked at\"], [2372, 2377, \"Companies worked at\"], [2208, 2213, \"Companies worked at\"], [1690, 1695, \"Companies worked at\"], [1677, 1688, \"Designation\"], [1638, 1647, \"Location\"], [1361, 1366, \"Companies worked at\"], [1233, 1238, \"Companies worked at\"], [72, 126, \"Email Address\"], [37, 46, \"Location\"], [30, 35, \"Companies worked at\"], [16, 27, \"Designation\"], [0, 15, \"Name\"]]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuEkwmYuHNx0",
        "outputId": "64e882e7-65cb-427c-a626-f5b01846fb42"
      },
      "source": [
        "type(json.dumps(converted_resumes[27][1][\"entities\"]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXx23PxAjPBj"
      },
      "source": [
        "__Task 5__: Explain the printout from above.<br>\n",
        "\n",
        "With json.dumps we can compactly encode into a json format. The above print shows actually one long string with many tuples, in which each tuple holds (start, end, text) for all the labels in annotation for each CV.\n",
        "\n",
        "<br>\n",
        "\n",
        "__Task 6__: Since some resumees have no annotation, we want to filter these out. You can recognize these resumees by them having no entries in __entities__. Pick one of the remaining resumees, iterate over the items in __entitities__, print for each item the label and the corresponding text from the resumee."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KjAdqTckp41"
      },
      "source": [
        "# TODO filter out the resumees whose entities have no entries.\n",
        "converted_complete_resumees = [(text, ent) for text, ent in converted_resumes if len(ent[\"entities\"]) > 0]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al0x9iyBk-qs",
        "outputId": "e2a1fdda-4a23-48c0-c502-8ccb74bc87af"
      },
      "source": [
        "print( len( converted_complete_resumees ) )"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qys_4RJ6nCCj",
        "outputId": "9c04b5bf-6c19-4d1a-d044-0101ccc302e8"
      },
      "source": [
        "# TODO Now, pick one resumee from converted_complete_resumees, and iterate over the items in \n",
        "# entities. Print for each item the label and the corresponding text from the resumee.\n",
        "\n",
        "for start, end, ent in converted_complete_resumees[27][1][\"entities\"]:\n",
        "  print(f\"[{ent}]: {converted_complete_resumees[27][0][start:end]}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Companies worked at]: Cisco\n",
            "[Skills]: • Programming Languages: Python, XML\n",
            "• Database: Maria-DB, sql\n",
            "• Cisco Monitoring Tools: EM7\n",
            "• Operating Systems: Windows/XP\n",
            "• Reporting Tools: Vportal, Splunk\n",
            "• Application & Web Servers: Sciencelogic (EM7), Syslog sender, Relay server.\n",
            "• Data Structure Knowledge: Intermediate\n",
            "[Skills]: Database (3 years), Python (3 years), Splunk (Less than 1 year), SQL (3 years), xml (3 years)\n",
            "\n",
            "[Graduation Year]: 2012\n",
            "[College Name]: rajasthan University\n",
            "\n",
            "[College Name]: Compucom Insitute of Information Technology\n",
            "\n",
            "[Companies worked at]: Cisco\n",
            "[Designation]: Team Member\n",
            "[Companies worked at]: Cisco\n",
            "[Companies worked at]: Cisco\n",
            "[Companies worked at]: Cisco\n",
            "[Companies worked at]: Cisco\n",
            "[Designation]: Team Member\n",
            "[Location]: Bengaluru\n",
            "[Companies worked at]: Cisco\n",
            "[Companies worked at]: Cisco\n",
            "[Email Address]: Indeed: indeed.com/r/Kasturika-\n",
            "Borah/9e71468914b38ee8\n",
            "[Location]: Bengaluru\n",
            "[Companies worked at]: Cisco\n",
            "[Designation]: Team Member\n",
            "[Name]: Kasturika Borah\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJCOSsZJtDnA"
      },
      "source": [
        "__Question 3__: Are the labels unique? If the labels are not unique, does this make the data ambigious?<br>\n",
        "\n",
        "The labels are not unique. Companies worked at for example typically holds multiple companies. Furthermore one candidate typically has more than one skill. Still, this is no problem, because we want to do entity recognition, and each word will be evaluated seperately, so multiple same labels can be predicted.\n",
        "\n",
        "<br>\n",
        "\n",
        "__Task 7__: Collect the names of all entities in __converted_complete_resumee__ dataset, and store these names in __all_labels__. Then iterate over the contents of __all_labels__, and store each name that does not appear in __unique_labels__ in __unique_labels__, so that __unique_labels__ contains each name that appears in __all_labels__, but only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8N5z6OutflX",
        "outputId": "725bec65-80b1-4c69-ad01-8a8f628f4b9d"
      },
      "source": [
        "# TODO Collect the names of all entities in converted_complete_resumee dataset, and store these names \n",
        "# in all_labels. Then iterate over the contents of all_labels, and store each name that does not appear \n",
        "# in unique_labels in unique_labels, so that unique_labels contains each name that appears in \n",
        "# all_labels, but only once.\n",
        "all_labels = []\n",
        "\n",
        "unique_labels = []\n",
        "\n",
        "for res in converted_complete_resumees:\n",
        "  try:\n",
        "    [unique_labels.append(item[2]) for item in res[1][\"entities\"]]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "unique_labels = set(unique_labels)\n",
        "\n",
        "for item in unique_labels:\n",
        "  print( item )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Location\n",
            "College\n",
            "Skills\n",
            "Can Relocate to\n",
            "Certifications\n",
            "Links\n",
            "state\n",
            "Rewards and Achievements\n",
            "projects\n",
            "UNKNOWN\n",
            "Name\n",
            "College Name\n",
            "Graduation Year\n",
            "Degree\n",
            "abc\n",
            "Email Address\n",
            "Relocate to\n",
            "University\n",
            "Years of Experience\n",
            "Companies worked at\n",
            "training\n",
            "des\n",
            "Designation\n",
            "Address\n",
            "links\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxJ_ZC6Zv0q1"
      },
      "source": [
        "__Task 8__: Now choose three labels, on which you want to train your named entity recognition algorithm. You want to have for each label at least 300 documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KgZMpQTwiIu",
        "outputId": "62092a5a-68a1-4f71-f8ba-e37f2c242713"
      },
      "source": [
        "## TODO store entity label names for the entities you want to work with in an array \n",
        "chosen_entity_label = [ \"Degree\", \"Companies worked at\", \"Skills\" ]\n",
        "## for each chosen entity label, count how many documents have a labeled entity for that label, and how many labeled entities total there are \n",
        "## for that entity\n",
        "for chosen in chosen_entity_label:\n",
        "    found_docs_with_entity = 0\n",
        "    entity_count = 0\n",
        "    for resume in converted_complete_resumees:\n",
        "        entity_list = resume[1][\"entities\"]\n",
        "        _,_,labels = zip(*entity_list)\n",
        "        if chosen in labels:\n",
        "            found_docs_with_entity+=1\n",
        "            entity_count+=len([l for l in labels if l == chosen])\n",
        "    print(\"Docs with {}: {}\".format(chosen,found_docs_with_entity))\n",
        "    print(\"Total count of {}: {}\".format(chosen,entity_count))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Docs with Degree: 606\n",
            "Total count of Degree: 1012\n",
            "Docs with Companies worked at: 627\n",
            "Total count of Companies worked at: 2830\n",
            "Docs with Skills: 536\n",
            "Total count of Skills: 2152\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}